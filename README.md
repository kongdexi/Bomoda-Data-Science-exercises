# Bomoda-Data-Science-exercises
Given the data archive located at https://drive.google.com/file/d/0B5ADI2usunVQOGU5RE5tT281Tzg/view?usp=sharing , using either Python or Scala, devise solutions to the following set of problems:

1. Word count I: 
  a: Count the number of posts mentioning each of the included brand names as well as the users who mentioned them. Hint: Pay attention to the variation of names. 
  b: List the top 10 users and locations (as province level in China and nation level worldwide) for total posts.

2. Word count II: 
  a: Find the date that has the highest number of posts mentioning each of the brands
  b: Find the peak hour with the most posts. 

3. Word count III: 
  Tokenize the comments and retrieve the top 10 mentioned Chinese terms associated with each brand from the texts. You may use 3rd party libraries such as Jieba to complete this task.

 4: Count & Visualize:
  a: Count the number of reposts and comments per day (as separate counts), per brand
  b: Plot the count over the entire timeframe

5. Sampling: 
  Explain possible sampling bias through Weibo, such as gender bias, etc.

6. What are some possible algorithms to identify users who showed interest in Michael Kors over Kate Spade? What are some data points that can be used to illustrate the algorithm's utility? Give a couple examples and discuss pros and cons. (You do not have to code here)
